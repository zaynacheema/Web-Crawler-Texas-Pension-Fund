{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaynacheema/Web-Crawler-Texas-Pension-Fund/blob/Dev/Notebooks/Web_Crawler_TRS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install necessary libraries and packages\n",
        "!pip install duckduckgo-search requests-html nest-asyncio\n",
        "!pip install requests-html"
      ],
      "metadata": {
        "id": "_8SpOi5oBwP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code searches DuckDuckGo for a specific query, in this case, TRS board meeting webcasts, using the DDGS library\n",
        "# and retrieves relevant URLs. It then fetches and renders the webpages using AsyncHTMLSession, parsing them with BeautifulSoup to\n",
        "# find Mediasite video links. The entire process runs asynchronously to gather results efficiently. Finally, it prints and returns\n",
        "# any Mediasite links found from the top search results."
      ],
      "metadata": {
        "id": "KBcERoINDkqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from duckduckgo_search import DDGS\n",
        "from bs4 import BeautifulSoup\n",
        "from requests_html import AsyncHTMLSession\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "from pprint import pprint\n",
        "import random\n",
        "import time\n",
        "\n",
        "#to allow asyncio to work in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def search_duckduckgo(query, max_results=5):\n",
        "    with DDGS() as ddgs:\n",
        "        results = list(ddgs.text(query, max_results=max_results))\n",
        "    print(f\"Search results for: {query}\")\n",
        "    urls = []\n",
        "    for r in results:\n",
        "        print(f\"Result URL: {r['href']}\")\n",
        "        urls.append(r['href'])\n",
        "    return urls\n",
        "\n",
        "async def fetch_mediasite_links(url):\n",
        "    session = AsyncHTMLSession()\n",
        "    try:\n",
        "        response = await session.get(url)\n",
        "        await response.html.arender()\n",
        "        soup = BeautifulSoup(response.html.html, 'html.parser')\n",
        "        mediasite_links = []\n",
        "        for link in soup.find_all('a'):\n",
        "            href = link.get('href')\n",
        "            if href and 'mediasite' in href:\n",
        "                mediasite_links.append(href)\n",
        "                print('Mediasite link found:', href)\n",
        "        if not mediasite_links:\n",
        "            print(f\"No Mediasite links found in {url}\")\n",
        "        return mediasite_links\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "        return []\n",
        "\n",
        "async def main(urls):\n",
        "    tasks = [fetch_mediasite_links(url) for url in urls]\n",
        "    results = await asyncio.gather(*tasks)\n",
        "    return [link for sublist in results for link in sublist]\n",
        "\n",
        "def search_and_crawl(query, max_results=3):\n",
        "    urls = search_duckduckgo(query, max_results)\n",
        "    if not urls:\n",
        "        print(f\"No results found for query: {query}\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Fetching Mediasite links from top {len(urls)} results...\")\n",
        "    results = asyncio.run(main(urls))\n",
        "    return results\n",
        "\n",
        "#usage\n",
        "query = 'TRS board meeting webcasts'\n",
        "result = search_and_crawl(query)\n",
        "pprint(result)"
      ],
      "metadata": {
        "id": "cWuZ-5n3BwbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this code is a pseudo-version of above, it pulls all Mediasite/video links from a page, in this case, TRS, or the Teacher Retirement System of Texas\n",
        "#It ultimately goes through a page and pulls all video links hosted on Mediasite Player and retrieves their URLs."
      ],
      "metadata": {
        "id": "abz_66ZnDUiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from requests_html import AsyncHTMLSession\n",
        "from bs4 import BeautifulSoup\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "#to allow asyncio to work in Jupyter environments like Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def fetch_mediasite_links(url):\n",
        "    session = AsyncHTMLSession()\n",
        "\n",
        "    #make request to the page\n",
        "    response = await session.get(url)\n",
        "\n",
        "    #render the JavaScript\n",
        "    await response.html.arender()\n",
        "\n",
        "    #parse the rendered HTML with BeautifulSoup\n",
        "    soup = BeautifulSoup(response.html.html, 'html.parser')\n",
        "\n",
        "    #extract Mediasite links\n",
        "    mediasite_links = []\n",
        "    for link in soup.find_all('a'):\n",
        "        href = link.get('href')\n",
        "        if href and 'mediasite' in href:\n",
        "            mediasite_links.append(href)\n",
        "            print('Mediasite link found:', href)\n",
        "\n",
        "    if not mediasite_links:\n",
        "        print(\"No Mediasite links found.\")\n",
        "    return mediasite_links\n",
        "\n",
        "#function to run the async code and handle event loop\n",
        "async def main(url):\n",
        "    return await fetch_mediasite_links(url)\n",
        "\n",
        "#execute\n",
        "url = 'https://www.trs.texas.gov/Pages/board_meeting_webcasts.aspx'\n",
        "result = await main(url)\n"
      ],
      "metadata": {
        "id": "HGVJcxJ6CBHn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}